{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  High Performance ML Algorithms (HPMLA).\n",
    "\n",
    "## Instructions\n",
    "\n",
    "### Install Dependencies and Create Configuration file.\n",
    "Follow [instructions](https://github.com/Azure/BatchAI/tree/master/recipes) to install all dependencies and create configuration file.\n",
    "Use `utilities.py` and `configuration.json.template` from [here](https://github.com/Azure/BatchAI/tree/master/recipes). Fill the values in `configuration.json` using the template and the instructions link.\n",
    "Make sure `utilities.py` is in the current directory or `PYTHONPATH` of the running jupyter notebook. \n",
    "Make sure `configuration.json` that you create is in the current directory or give the full path of `configuration.json` in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Configuration and Create Batch AI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "bfa11f00-8866-4051-bbfe-a9646e004910"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "from azure.storage.file import FileService\n",
    "from azure.storage.blob import BlockBlobService\n",
    "import azure.mgmt.batchai.models as models\n",
    "\n",
    "sys.path.append('../../')\n",
    "import utilities as utils\n",
    "\n",
    "from azure.storage.file import FileService\n",
    "cfg = utils.config.Configuration('configuration.json')\n",
    "client = utils.config.create_batchai_client(cfg)\n",
    "nodeCount = 3\n",
    "threadPerNode = 1\n",
    "datasetblobpath = 'criteo-libsvm-uniform'\n",
    "datasetsharepath = 'criteo-libsvm-uniform-share'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Batch AI workspace if not exists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = client.workspaces.create(cfg.resource_group, cfg.workspace, cfg.location).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create File Share\n",
    "\n",
    "For this example we will create a new file share to use for output data.\n",
    "\n",
    "**Note** You don't need to create a share every cluster or a job you deploy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_file_share_name = datasetsharepath\n",
    "file_service = FileService(cfg.storage_account_name, cfg.storage_account_key)\n",
    "file_service.create_share(azure_file_share_name, fail_on_exist=False)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Azure Batch AI Compute Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Compute Cluster\n",
    "\n",
    "- For this example we will use a GPU cluster of `STANDARD_NC24S_V3` nodes. Number of nodes in the cluster is configured with `nodes_count` variable;\n",
    "- We will call the cluster `symsgdaicluster_nc24s_3`. But you should replace this and the `nodes_count` to whatever the name of your cluster is and its nodes_count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_count = nodeCount\n",
    "cluster_name = 'symsgdaicluster_nc24s_3'\n",
    "\n",
    "parameters = models.ClusterCreateParameters(\n",
    "    vm_size='STANDARD_NC24S_V3',\n",
    "    scale_settings=models.ScaleSettings(\n",
    "        manual=models.ManualScaleSettings(target_node_count=nodes_count)\n",
    "    ),\n",
    "    user_account_settings=models.UserAccountSettings(\n",
    "        admin_user_name=cfg.admin,\n",
    "        admin_user_password=cfg.admin_password or None,\n",
    "        admin_user_ssh_public_key=cfg.admin_ssh_key or None,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Compute Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You only need this if you do not have existing cluster. If you have a cluster then remove this step but mount the volumes\n",
    "client.clusters.create(cfg.resource_group, cfg.workspace, cluster_name, parameters).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.config.credentials.id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor Cluster Creation\n",
    "\n",
    "utilities.py contains a helper function allowing to wait for the cluster to become available - all nodes are allocated and finished preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cluster = client.clusters.get(cfg.resource_group, cfg.workspace, cluster_name)\n",
    "utils.cluster.print_cluster_status(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Azure Batch AI Training Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Input Directories\n",
    "\n",
    "The job needs input and output directories which we will add. They are not needed and I will take them out in future since we give the full path to `supersgd` anyways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Output Directories\n",
    "We will store standard and error output of the job in one of the directories in output blob:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nodeCount)\n",
    "print(threadPerNode)\n",
    "input_directories = []\n",
    "output_directories=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.mgmt.batchai.models.image_source_registry import ImageSourceRegistry\n",
    "azure_file_share_mount_path = azure_file_share_name\n",
    "azure_blob_work_mount_path = datasetblobpath\n",
    "\n",
    "parameters = models.JobCreateParameters(\n",
    "     cluster=models.ResourceId(id=cluster.id),\n",
    "     node_count=nodes_count,\n",
    "     output_directories=[\n",
    "        models.OutputDirectory(\n",
    "            id='MODEL',\n",
    "            path_prefix='$AZ_BATCHAI_JOB_MOUNT_ROOT/{0}'.format(\n",
    "                azure_file_share_mount_path),\n",
    "            path_suffix='models')\n",
    "    ],\n",
    "    input_directories=[\n",
    "        models.InputDirectory(\n",
    "            id='DATASET',\n",
    "            path='$AZ_BATCHAI_JOB_MOUNT_ROOT/{0}/{1}'.format(azure_blob_work_mount_path, 'part-')),\n",
    "        models.InputDirectory(\n",
    "            id='MODEL',\n",
    "            path='$AZ_BATCHAI_JOB_MOUNT_ROOT/{0}/{1}'.format(azure_blob_work_mount_path, 'models')),\n",
    "    ],\n",
    "    std_out_err_path_prefix='$AZ_BATCHAI_JOB_MOUNT_ROOT/{0}'.format(azure_file_share_mount_path),\n",
    "    mount_volumes=models.MountVolumes(\n",
    "        azure_file_shares=[\n",
    "            models.AzureFileShareReference(\n",
    "                account_name=cfg.storage_account_name,\n",
    "                credentials=models.AzureStorageCredentialsInfo(\n",
    "                    account_key=cfg.storage_account_key),\n",
    "                azure_file_url='https://{0}.file.core.windows.net/{1}'.format(\n",
    "                    cfg.storage_account_name, azure_file_share_mount_path),\n",
    "                relative_mount_path=azure_file_share_mount_path)\n",
    "        ],\n",
    "        azure_blob_file_systems=[\n",
    "            models.AzureBlobFileSystemReference(\n",
    "                account_name=cfg.storage_account_name,\n",
    "                credentials=models.AzureStorageCredentialsInfo(\n",
    "                    account_key=cfg.storage_account_key),\n",
    "                container_name=azure_blob_work_mount_path,\n",
    "                relative_mount_path=azure_blob_work_mount_path),\n",
    "        ],\n",
    "    ),\n",
    "     container_settings=models.ContainerSettings(\n",
    "         image_source_registry=models.ImageSourceRegistry(\n",
    "             image='msmadl/symsgd:0.0.2')),\n",
    "     job_preparation=models.JobPreparation(\n",
    "         command_line=\"ls\"),\n",
    "     custom_toolkit_settings = models.CustomToolkitSettings(\n",
    "    command_line=\"mpirun --allow-run-as-root -mca btl_tcp_if_exclude docker0 --hostfile $AZ_BATCHAI_MPI_HOST_FILE -np 3 /parasail/supersgd -l 1e-4 -k 32 -mc 1e-2 -e 10 -r 10 -f $AZ_BATCHAI_INPUT_DATASET -t 1 -gl 1 -glDir $AZ_BATCHAI_OUTPUT_MODEL -mem -bd $AZ_BATCHAI_INPUT_DATASET\"\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a training Job and wait for Job completion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment_name = 'parasail_experiment'\n",
    "experiment = client.experiments.create(cfg.resource_group, cfg.workspace, experiment_name).result()\n",
    "job_name = datetime.utcnow().strftime('tf_%m_%d_%Y_%H%M%S')\n",
    "job = client.jobs.create(cfg.resource_group, cfg.workspace, experiment_name, job_name, parameters).result()\n",
    "print('Created Job {0} in Experiment {1}'.format(job.name, experiment.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait for Job to Finish\n",
    "The job will start running when the cluster will have enough idle nodes. The following code waits for job to start running printing the cluster state. During job run, the code prints current content of stdeout-0.txt (the output of the worker running on the first node)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.job.wait_for_job_completion(client, cfg.resource_group, cfg.workspace, \n",
    "                                  experiment_name, job_name, cluster_name, 'stdouterr', 'stdout-wk-0.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### List stdout.txt and stderr.txt files for the Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = client.jobs.list_output_files(cfg.resource_group, cfg.workspace, experiment_name, job_name,\n",
    "                                      models.JobsListOutputFilesOptions(outputdirectoryid='stdouterr')) \n",
    "for f in list(files):\n",
    "    print(f.name, f.download_url or 'directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
